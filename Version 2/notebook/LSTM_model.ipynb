{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c12c349-bc39-4000-bb8e-eaef2acc14a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f11ac5c-305f-4652-a1c5-562282582d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target</th>\n",
       "      <th>RAV</th>\n",
       "      <th>volatility</th>\n",
       "      <th>Buy_Sell_Strength</th>\n",
       "      <th>Weighted_Strength</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Returns</th>\n",
       "      <th>Log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_rank</th>\n",
       "      <th>return_rank</th>\n",
       "      <th>lag_market_return</th>\n",
       "      <th>market_std</th>\n",
       "      <th>zscore_vs_market</th>\n",
       "      <th>return_1</th>\n",
       "      <th>return_2</th>\n",
       "      <th>vol_3</th>\n",
       "      <th>close_z</th>\n",
       "      <th>market_mean_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-06</th>\n",
       "      <td>26.495502</td>\n",
       "      <td>174826400</td>\n",
       "      <td>1</td>\n",
       "      <td>2.508224e+08</td>\n",
       "      <td>1.046603</td>\n",
       "      <td>0.266668</td>\n",
       "      <td>-0.162635</td>\n",
       "      <td>-0.007055</td>\n",
       "      <td>-0.008421</td>\n",
       "      <td>8.064542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>-0.131420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-06</th>\n",
       "      <td>36.218147</td>\n",
       "      <td>34616600</td>\n",
       "      <td>0</td>\n",
       "      <td>5.097210e+07</td>\n",
       "      <td>2.133879</td>\n",
       "      <td>0.406248</td>\n",
       "      <td>-0.063670</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>10.087206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>0.991042</td>\n",
       "      <td>-0.008421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-06</th>\n",
       "      <td>0.489517</td>\n",
       "      <td>210524000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.155857e+08</td>\n",
       "      <td>0.010619</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>-0.268543</td>\n",
       "      <td>0.023777</td>\n",
       "      <td>-0.004392</td>\n",
       "      <td>-0.689525</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>0.473265</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>-0.008421</td>\n",
       "      <td>1.063700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-06</th>\n",
       "      <td>14.490667</td>\n",
       "      <td>48658500</td>\n",
       "      <td>1</td>\n",
       "      <td>5.486293e+07</td>\n",
       "      <td>0.608197</td>\n",
       "      <td>0.124639</td>\n",
       "      <td>-0.332912</td>\n",
       "      <td>0.016009</td>\n",
       "      <td>-0.016426</td>\n",
       "      <td>5.386730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>-1.332886</td>\n",
       "      <td>-0.004392</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>0.917565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-09</th>\n",
       "      <td>26.671505</td>\n",
       "      <td>155559200</td>\n",
       "      <td>1</td>\n",
       "      <td>2.247958e+08</td>\n",
       "      <td>1.096023</td>\n",
       "      <td>0.914897</td>\n",
       "      <td>0.287110</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>8.139063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>1.466347</td>\n",
       "      <td>-0.016426</td>\n",
       "      <td>-0.004392</td>\n",
       "      <td>0.571613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Close     Volume  Target           RAV  volatility  \\\n",
       "Date                                                                 \n",
       "2015-02-06  26.495502  174826400       1  2.508224e+08    1.046603   \n",
       "2015-02-06  36.218147   34616600       0  5.097210e+07    2.133879   \n",
       "2015-02-06   0.489517  210524000       0  2.155857e+08    0.010619   \n",
       "2015-02-06  14.490667   48658500       1  5.486293e+07    0.608197   \n",
       "2015-02-09  26.671505  155559200       1  2.247958e+08    1.096023   \n",
       "\n",
       "            Buy_Sell_Strength  Weighted_Strength     Trend   Returns  \\\n",
       "Date                                                                   \n",
       "2015-02-06           0.266668          -0.162635 -0.007055 -0.008421   \n",
       "2015-02-06           0.406248          -0.063670  0.022419 -0.000943   \n",
       "2015-02-06           0.225000          -0.268543  0.023777 -0.004392   \n",
       "2015-02-06           0.124639          -0.332912  0.016009 -0.016426   \n",
       "2015-02-09           0.914897           0.287110  0.010177  0.006643   \n",
       "\n",
       "            Log_returns  ...  volume_rank  return_rank  lag_market_return  \\\n",
       "Date                     ...                                                \n",
       "2015-02-06     8.064542  ...         0.75         0.50                NaN   \n",
       "2015-02-06    10.087206  ...         0.25         1.00          -0.007546   \n",
       "2015-02-06    -0.689525  ...         1.00         0.75          -0.007546   \n",
       "2015-02-06     5.386730  ...         0.50         0.25          -0.007546   \n",
       "2015-02-09     8.139063  ...         0.75         1.00                NaN   \n",
       "\n",
       "            market_std  zscore_vs_market  return_1  return_2     vol_3  \\\n",
       "Date                                                                     \n",
       "2015-02-06    0.006663         -0.131420       NaN       NaN       NaN   \n",
       "2015-02-06    0.006663          0.991042 -0.008421       NaN       NaN   \n",
       "2015-02-06    0.006663          0.473265 -0.000943 -0.008421  1.063700   \n",
       "2015-02-06    0.006663         -1.332886 -0.004392 -0.000943  0.917565   \n",
       "2015-02-09    0.003672          1.466347 -0.016426 -0.004392  0.571613   \n",
       "\n",
       "            close_z  market_mean_return  \n",
       "Date                                     \n",
       "2015-02-06      NaN           -0.007546  \n",
       "2015-02-06      NaN           -0.007546  \n",
       "2015-02-06      NaN           -0.007546  \n",
       "2015-02-06      NaN           -0.007546  \n",
       "2015-02-09      NaN            0.001259  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/engineered_interleaved_features_multi_stock_data.csv\",index_col=\"Date\")\n",
    "df.drop([\"Unnamed: 0\"],axis=\"columns\",inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8750a228-725d-4e63-ad5e-151c997fd0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10764 entries, 2015-02-06 to 2025-10-17\n",
      "Data columns (total 28 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Close               10764 non-null  float64\n",
      " 1   Volume              10764 non-null  int64  \n",
      " 2   Target              10764 non-null  int64  \n",
      " 3   RAV                 10764 non-null  float64\n",
      " 4   volatility          10764 non-null  float64\n",
      " 5   Buy_Sell_Strength   10764 non-null  float64\n",
      " 6   Weighted_Strength   10764 non-null  float64\n",
      " 7   Trend               10764 non-null  float64\n",
      " 8   Returns             10764 non-null  float64\n",
      " 9   Log_returns         10764 non-null  float64\n",
      " 10  AAPL                10764 non-null  bool   \n",
      " 11  MSFT                10764 non-null  bool   \n",
      " 12  NVDA                10764 non-null  bool   \n",
      " 13  TSLA                10764 non-null  bool   \n",
      " 14  market_return       10764 non-null  float64\n",
      " 15  rel_return          10764 non-null  float64\n",
      " 16  mean_return_others  10764 non-null  float64\n",
      " 17  divergence          10764 non-null  float64\n",
      " 18  volume_rank         10764 non-null  float64\n",
      " 19  return_rank         10764 non-null  float64\n",
      " 20  lag_market_return   8073 non-null   float64\n",
      " 21  market_std          10764 non-null  float64\n",
      " 22  zscore_vs_market    10764 non-null  float64\n",
      " 23  return_1            10763 non-null  float64\n",
      " 24  return_2            10762 non-null  float64\n",
      " 25  vol_3               10762 non-null  float64\n",
      " 26  close_z             10755 non-null  float64\n",
      " 27  market_mean_return  10764 non-null  float64\n",
      "dtypes: bool(4), float64(22), int64(2)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bd35393-1a8d-499d-ac4c-17ec11340c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e7e802b-f048-4119-9427-0b7b9712f1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10764 10764\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Target','lag_market_return','close_z', 'vol_3', 'return_2', 'return_1',\"market_mean_return\"], axis=\"columns\")\n",
    "y = np.array(df['Target'])\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc193a6f-4df6-4695-b5f6-a88e182b6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7534 1615 1615 7534 1615 1615\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(X) * 0.70)\n",
    "val_size = int(len(X) * 0.85)\n",
    "X_train, X_val, X_test = X[0:train_size], X[train_size:val_size], X[val_size:len(X)]\n",
    "y_train, y_val, y_test = y[0:train_size], y[train_size:val_size], y[val_size:len(y)]\n",
    "print(len(X_train), len(X_test), len(X_val), len(y_train), len(y_test), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba12f730-2fb5-43c5-b709-80b036a6704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "X_val_scaled  = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df906383-6b77-4afe-91e0-4c6547a75f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_sequence(X, y, time_stamp=5):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_stamp):\n",
    "        Xs.append(X[i:(i + time_stamp)])\n",
    "        ys.append(y[i + time_stamp])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e75702b5-1281-49f5-be9c-a2eba2c399ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7514, 20, 21) (7514,)\n",
      "(1595, 20, 21) (1595,)\n",
      "(1595, 20, 21) (1595,)\n"
     ]
    }
   ],
   "source": [
    "time_stamp = 20\n",
    "features = len(X.columns)\n",
    "X_train_seq, y_train_seq = creat_sequence(X_train_scaled, y_train, time_stamp)\n",
    "X_val_seq, y_val_seq = creat_sequence(X_val_scaled, y_val, time_stamp)\n",
    "X_test_seq, y_test_seq = creat_sequence(X_test_scaled, y_test, time_stamp)\n",
    "\n",
    "print(X_train_seq.shape, y_train_seq.shape)\n",
    "print(X_val_seq.shape, y_val_seq.shape)\n",
    "print(X_test_seq.shape, y_test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "311e5541-7214-42c2-9f00-e95bb5d72492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence 0\n",
      "X window indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Target index: 20\n",
      "y target: 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "sequence 1\n",
      "X window indices: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "Target index: 21\n",
      "y target: 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "sequence 2\n",
      "X window indices: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "Target index: 22\n",
      "y target: 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "sequence 3\n",
      "X window indices: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Target index: 23\n",
      "y target: 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "sequence 4\n",
      "X window indices: [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "Target index: 24\n",
      "y target: 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"sequence {i}\")\n",
    "    print(\"X window indices:\", list(range(i, i + time_stamp)))\n",
    "    print(\"Target index:\", i + time_stamp)\n",
    "    print(\"y target:\", y[i + time_stamp])\n",
    "    print(\"-\" * 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d0ac5704-0ec4-4826-913a-dba8273c0ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.5268 - loss: 0.6941 - val_accuracy: 0.5191 - val_loss: 0.6926\n",
      "Epoch 2/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5258 - loss: 0.6915 - val_accuracy: 0.5191 - val_loss: 0.6960\n",
      "Epoch 3/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5283 - loss: 0.6917 - val_accuracy: 0.5191 - val_loss: 0.6931\n",
      "Epoch 4/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5325 - loss: 0.6915 - val_accuracy: 0.5191 - val_loss: 0.6928\n",
      "Epoch 5/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5325 - loss: 0.6914 - val_accuracy: 0.5191 - val_loss: 0.6930\n",
      "Epoch 6/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5325 - loss: 0.6915 - val_accuracy: 0.5191 - val_loss: 0.6924\n",
      "Epoch 7/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5325 - loss: 0.6913 - val_accuracy: 0.5191 - val_loss: 0.6926\n",
      "Epoch 8/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5325 - loss: 0.6913 - val_accuracy: 0.5191 - val_loss: 0.6925\n",
      "Epoch 9/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5325 - loss: 0.6912 - val_accuracy: 0.5191 - val_loss: 0.6930\n",
      "Epoch 10/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5305 - loss: 0.6913 - val_accuracy: 0.5191 - val_loss: 0.6929\n",
      "Epoch 11/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5305 - loss: 0.6911 - val_accuracy: 0.5191 - val_loss: 0.6928\n",
      "Epoch 12/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5325 - loss: 0.6911 - val_accuracy: 0.5191 - val_loss: 0.6929\n",
      "Epoch 13/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5339 - loss: 0.6905 - val_accuracy: 0.5179 - val_loss: 0.6944\n",
      "Epoch 14/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5330 - loss: 0.6909 - val_accuracy: 0.5191 - val_loss: 0.6925\n",
      "Epoch 15/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.5325 - loss: 0.6910 - val_accuracy: 0.5191 - val_loss: 0.6926\n",
      "Epoch 16/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.5309 - loss: 0.6903 - val_accuracy: 0.5191 - val_loss: 0.6939\n",
      "Epoch 17/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.5317 - loss: 0.6901 - val_accuracy: 0.5141 - val_loss: 0.6939\n",
      "Epoch 18/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5314 - loss: 0.6899 - val_accuracy: 0.5172 - val_loss: 0.6928\n",
      "Epoch 19/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.5379 - loss: 0.6894 - val_accuracy: 0.5191 - val_loss: 0.6926\n",
      "Epoch 20/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.5297 - loss: 0.6895 - val_accuracy: 0.5223 - val_loss: 0.6925\n",
      "Epoch 21/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5382 - loss: 0.6876 - val_accuracy: 0.5154 - val_loss: 0.6925\n",
      "Epoch 22/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5310 - loss: 0.6877 - val_accuracy: 0.5166 - val_loss: 0.6953\n",
      "Epoch 23/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5358 - loss: 0.6875 - val_accuracy: 0.5166 - val_loss: 0.6925\n",
      "Epoch 24/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5354 - loss: 0.6863 - val_accuracy: 0.5191 - val_loss: 0.6925\n",
      "Epoch 25/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5394 - loss: 0.6865 - val_accuracy: 0.5210 - val_loss: 0.6924\n",
      "Epoch 26/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5389 - loss: 0.6853 - val_accuracy: 0.4796 - val_loss: 0.6972\n",
      "Epoch 27/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5478 - loss: 0.6842 - val_accuracy: 0.4966 - val_loss: 0.7004\n",
      "Epoch 28/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5468 - loss: 0.6846 - val_accuracy: 0.5110 - val_loss: 0.6931\n",
      "Epoch 29/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5484 - loss: 0.6821 - val_accuracy: 0.5085 - val_loss: 0.7031\n",
      "Epoch 30/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5588 - loss: 0.6810 - val_accuracy: 0.5166 - val_loss: 0.7005\n",
      "Epoch 31/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5648 - loss: 0.6789 - val_accuracy: 0.5034 - val_loss: 0.7193\n",
      "Epoch 32/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5719 - loss: 0.6770 - val_accuracy: 0.4834 - val_loss: 0.7039\n",
      "Epoch 33/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5721 - loss: 0.6746 - val_accuracy: 0.5085 - val_loss: 0.6979\n",
      "Epoch 34/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5755 - loss: 0.6735 - val_accuracy: 0.4940 - val_loss: 0.7083\n",
      "Epoch 35/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5894 - loss: 0.6690 - val_accuracy: 0.4972 - val_loss: 0.7067\n",
      "Epoch 36/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5934 - loss: 0.6662 - val_accuracy: 0.5041 - val_loss: 0.7096\n",
      "Epoch 37/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5968 - loss: 0.6606 - val_accuracy: 0.4884 - val_loss: 0.7353\n",
      "Epoch 38/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6099 - loss: 0.6552 - val_accuracy: 0.5097 - val_loss: 0.7246\n",
      "Epoch 39/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6157 - loss: 0.6508 - val_accuracy: 0.4940 - val_loss: 0.7445\n",
      "Epoch 40/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6106 - loss: 0.6497 - val_accuracy: 0.4947 - val_loss: 0.7378\n",
      "Epoch 41/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6349 - loss: 0.6372 - val_accuracy: 0.5009 - val_loss: 0.7725\n",
      "Epoch 42/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6433 - loss: 0.6252 - val_accuracy: 0.4947 - val_loss: 0.7684\n",
      "Epoch 43/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6448 - loss: 0.6227 - val_accuracy: 0.4846 - val_loss: 0.7715\n",
      "Epoch 44/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6585 - loss: 0.6116 - val_accuracy: 0.4909 - val_loss: 0.7777\n",
      "Epoch 45/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6689 - loss: 0.6042 - val_accuracy: 0.4984 - val_loss: 0.7806\n",
      "Epoch 46/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6684 - loss: 0.5958 - val_accuracy: 0.4878 - val_loss: 0.7743\n",
      "Epoch 47/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6958 - loss: 0.5767 - val_accuracy: 0.5028 - val_loss: 0.8993\n",
      "Epoch 48/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6975 - loss: 0.5675 - val_accuracy: 0.4915 - val_loss: 0.8554\n",
      "Epoch 49/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7088 - loss: 0.5604 - val_accuracy: 0.5009 - val_loss: 0.8664\n",
      "Epoch 50/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7155 - loss: 0.5494 - val_accuracy: 0.5047 - val_loss: 0.8699\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_49\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_49\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,016</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_98 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m22,016\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_99 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,565</span> (416.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m106,565\u001b[0m (416.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,521</span> (138.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,521\u001b[0m (138.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,044</span> (277.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m71,044\u001b[0m (277.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_crossentropy <keras.src.optimizers.adam.Adam object at 0x0000024244F277A0>\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(LSTM(units=64, input_shape=(time_stamp, features), return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(units=32, return_sequences=False))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(LSTM(units=16, return_sequences=False))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "# Add a Dense output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=0.005,  clipnorm=1.0)\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_seq,\n",
    "    y_train_seq,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    # callbacks=[early_stop]\n",
    ")\n",
    "model.summary()\n",
    "print(model.loss, model.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e6fea6c8-2a78-4723-8c4d-07c40f8fa806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 72ms/step - accuracy: 0.5301 - loss: 0.6943 - val_accuracy: 0.5191 - val_loss: 0.6942\n",
      "Epoch 2/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.5306 - loss: 0.6916 - val_accuracy: 0.5191 - val_loss: 0.6926\n",
      "Epoch 3/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.5295 - loss: 0.6913 - val_accuracy: 0.5191 - val_loss: 0.6926\n",
      "Epoch 4/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.5325 - loss: 0.6914 - val_accuracy: 0.5191 - val_loss: 0.6925\n",
      "Epoch 5/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.5325 - loss: 0.6917 - val_accuracy: 0.5191 - val_loss: 0.6929\n",
      "Epoch 6/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.5325 - loss: 0.6916 - val_accuracy: 0.5191 - val_loss: 0.6927\n",
      "Epoch 7/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.5306 - loss: 0.6917 - val_accuracy: 0.5191 - val_loss: 0.6925\n",
      "Epoch 8/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.5326 - loss: 0.6914 - val_accuracy: 0.5191 - val_loss: 0.6925\n",
      "Epoch 9/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.5341 - loss: 0.6903 - val_accuracy: 0.5141 - val_loss: 0.6950\n",
      "Epoch 10/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.5322 - loss: 0.6911 - val_accuracy: 0.5185 - val_loss: 0.6928\n",
      "Epoch 11/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.5334 - loss: 0.6905 - val_accuracy: 0.5166 - val_loss: 0.6933\n",
      "Epoch 12/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.5306 - loss: 0.6898 - val_accuracy: 0.5216 - val_loss: 0.6943\n",
      "Epoch 13/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.5378 - loss: 0.6890 - val_accuracy: 0.5191 - val_loss: 0.6929\n",
      "Epoch 14/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.5325 - loss: 0.6893 - val_accuracy: 0.5185 - val_loss: 0.6930\n",
      "Epoch 15/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.5383 - loss: 0.6882 - val_accuracy: 0.5122 - val_loss: 0.6945\n",
      "Epoch 16/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.5347 - loss: 0.6880 - val_accuracy: 0.4897 - val_loss: 0.6956\n",
      "Epoch 17/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.5339 - loss: 0.6895 - val_accuracy: 0.5078 - val_loss: 0.6952\n",
      "Epoch 18/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.5391 - loss: 0.6871 - val_accuracy: 0.4928 - val_loss: 0.6944\n",
      "Epoch 19/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.5415 - loss: 0.6879 - val_accuracy: 0.5266 - val_loss: 0.6920\n",
      "Epoch 20/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.5486 - loss: 0.6852 - val_accuracy: 0.5103 - val_loss: 0.6950\n",
      "Epoch 21/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.5463 - loss: 0.6856 - val_accuracy: 0.5298 - val_loss: 0.6957\n",
      "Epoch 22/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.5518 - loss: 0.6818 - val_accuracy: 0.5135 - val_loss: 0.6995\n",
      "Epoch 23/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.5538 - loss: 0.6809 - val_accuracy: 0.5097 - val_loss: 0.6943\n",
      "Epoch 24/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.5528 - loss: 0.6804 - val_accuracy: 0.4972 - val_loss: 0.6955\n",
      "Epoch 25/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.5649 - loss: 0.6774 - val_accuracy: 0.5417 - val_loss: 0.6970\n",
      "Epoch 26/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.5657 - loss: 0.6775 - val_accuracy: 0.5066 - val_loss: 0.7045\n",
      "Epoch 27/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.5846 - loss: 0.6729 - val_accuracy: 0.5197 - val_loss: 0.7038\n",
      "Epoch 28/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.5901 - loss: 0.6695 - val_accuracy: 0.5047 - val_loss: 0.7057\n",
      "Epoch 29/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.5960 - loss: 0.6649 - val_accuracy: 0.4959 - val_loss: 0.7206\n",
      "Epoch 30/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.5960 - loss: 0.6647 - val_accuracy: 0.4972 - val_loss: 0.7254\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_81\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_81\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">76,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_165 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_162 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_163 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_164 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m76,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_92 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_165 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_162 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_163 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384,965</span> (1.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m384,965\u001b[0m (1.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,321</span> (501.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128,321\u001b[0m (501.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256,644</span> (1002.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m256,644\u001b[0m (1002.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_crossentropy <keras.src.optimizers.adam.Adam object at 0x000002424E9E3C50>\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(LSTM(units=128, input_shape=(time_stamp, features), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=64, return_sequences=False))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(LSTM(units=32, return_sequences=False))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "# Add a Dense output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=0.005,  clipnorm=1.0)\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_seq,\n",
    "    y_train_seq,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    batch_size=64,\n",
    "    epochs=30,\n",
    "    # callbacks=[early_stop]\n",
    ")\n",
    "model.summary()\n",
    "print(model.loss, model.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "09925773-f871-47d8-9506-dc2e0b2d5c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5191 - loss: 0.7062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7061724066734314, 0.5191222429275513]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_seq,y_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2df14075-da59-4cf6-9ea0-3ca4d7b7a79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.53      0.50       735\n",
      "           1       0.56      0.51      0.53       860\n",
      "\n",
      "    accuracy                           0.52      1595\n",
      "   macro avg       0.52      0.52      0.52      1595\n",
      "weighted avg       0.52      0.52      0.52      1595\n",
      "\n",
      "[[390 345]\n",
      " [422 438]]\n",
      "[[0.58436704]\n",
      " [0.56382674]\n",
      " [0.51411784]\n",
      " [0.6737244 ]\n",
      " [0.6981603 ]]\n",
      "LSTM [812 783]\n"
     ]
    }
   ],
   "source": [
    "y_proba = model.predict(X_test_seq)  \n",
    "y_pred = (y_proba.ravel() >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test_seq, y_pred))\n",
    "print(confusion_matrix(y_test_seq, y_pred))\n",
    "print(y_proba[:5])\n",
    "print(\"LSTM\",np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e7a94954-95ca-4dcc-b364-25bc6011d839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/v3_lstm_stock_pediction.joblib']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model,'../models/v3_lstm_stock_pediction.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f1fb7528-ace9-4930-877e-e75cdd227212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5354 - loss: 0.7794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7794459462165833, 0.535423219203949]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_seq,y_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aab5e3ff-6f99-4f01-9905-f899f5e3e5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.53      0.51       735\n",
      "           1       0.57      0.54      0.56       860\n",
      "\n",
      "    accuracy                           0.54      1595\n",
      "   macro avg       0.53      0.53      0.53      1595\n",
      "weighted avg       0.54      0.54      0.54      1595\n",
      "\n",
      "[[388 347]\n",
      " [394 466]]\n",
      "[[0.26281497]\n",
      " [0.4501934 ]\n",
      " [0.57042277]\n",
      " [0.6980202 ]\n",
      " [0.83769405]]\n",
      "LSTM [782 813]\n"
     ]
    }
   ],
   "source": [
    "y_proba = model.predict(X_test_seq)  \n",
    "y_pred = (y_proba.ravel() >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test_seq, y_pred))\n",
    "print(confusion_matrix(y_test_seq, y_pred))\n",
    "print(y_proba[:5])\n",
    "print(\"LSTM\",np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f46308f4-a56d-4f0f-a71b-d011e89d689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close               0\n",
      "Volume              0\n",
      "zscore_vs_market    0\n",
      "market_std          0\n",
      "return_rank         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "print(scaled_df.isna().sum().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "717f4f76-53ee-46c1-8de3-554bd56c6c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close                 7358\n",
      "Volume                7503\n",
      "RAV                   7528\n",
      "volatility            7533\n",
      "Buy_Sell_Strength     7442\n",
      "Weighted_Strength     7530\n",
      "Trend                 7534\n",
      "Returns               7508\n",
      "Log_returns           7531\n",
      "AAPL                     2\n",
      "MSFT                     2\n",
      "NVDA                     2\n",
      "TSLA                     2\n",
      "market_return         1884\n",
      "rel_return            7533\n",
      "mean_return_others    1884\n",
      "divergence            7533\n",
      "volume_rank              4\n",
      "return_rank              5\n",
      "market_std            1884\n",
      "zscore_vs_market      7533\n",
      "market_mean_return    1884\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7828c36-1afc-4a66-a204-41391d6eda0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0.0 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X_train_scaled).sum())\n",
    "print(np.isinf(X_train_scaled).sum())\n",
    "print(X_train_scaled.min(), X_train_scaled.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aee433d8-7718-4ea0-b00a-1d30431a289b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "mask = np.isnan(y_train)\n",
    "print(mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9aec981c-7f48-4f52-8292-ecf9ea78d71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0.3140208522539836 0.3276449305495515\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X_train_seq).sum(), np.isinf(X_train_seq).sum())\n",
    "print(X_train_seq.std(), X_train_seq.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e1115203-91c4-4952-9e1e-8a3729e849bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, nan)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(norms), max(norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "be4a04c7-4ba1-4f65-b4ca-5be9ff7d9936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, nan)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "weights = model.trainable_weights\n",
    "norms = [np.linalg.norm(w.numpy()) for w in weights]\n",
    "min(norms), max(norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9ff52bbc-8e65-4547-88be-bae34773c149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Variable path=adamw/learning_rate, shape=(), dtype=float32, value=0.0010000000474974513>\n"
     ]
    }
   ],
   "source": [
    "print(model.optimizer.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2046bac2-0573-4306-8c11-38dcb81a043d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7534 1615 1615 7534 1615 1615\n",
      "(7514, 20, 7) (7514,)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.5220 - loss: 0.6926 - val_accuracy: 0.5191 - val_loss: 0.6926\n",
      "Epoch 2/50\n",
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.5325 - loss: 0.6915 - val_accuracy: 0.5191 - val_loss: 0.6927\n",
      "Epoch 3/50\n",
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.5325 - loss: 0.6913 - val_accuracy: 0.5191 - val_loss: 0.6925\n",
      "Epoch 4/50\n",
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.5315 - loss: 0.6913 - val_accuracy: 0.5191 - val_loss: 0.6924\n",
      "Epoch 5/50\n",
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.5314 - loss: 0.6913 - val_accuracy: 0.5191 - val_loss: 0.6924\n",
      "Epoch 6/50\n",
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.5325 - loss: 0.6912 - val_accuracy: 0.5191 - val_loss: 0.6924\n",
      "Epoch 7/50\n",
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.5314 - loss: 0.6912 - val_accuracy: 0.5191 - val_loss: 0.6924\n",
      "Epoch 8/50\n",
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.5325 - loss: 0.6913 - val_accuracy: 0.5191 - val_loss: 0.6924\n",
      "Epoch 9/50\n",
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.5311 - loss: 0.6913 - val_accuracy: 0.5191 - val_loss: 0.6924\n",
      "Epoch 10/50\n",
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 35ms/step - accuracy: 0.5325 - loss: 0.6912 - val_accuracy: 0.5191 - val_loss: 0.6924\n",
      "Epoch 11/50\n",
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.5314 - loss: 0.6913 - val_accuracy: 0.5191 - val_loss: 0.6924\n",
      "Epoch 12/50\n",
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.5325 - loss: 0.6913 - val_accuracy: 0.5191 - val_loss: 0.6924\n",
      "Epoch 13/50\n",
      "\u001b[1m470/470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5267 - loss: 0.6918"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[218], line 60\u001b[0m\n\u001b[0;32m     45\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[0;32m     46\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     47\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,        \n\u001b[0;32m     48\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(\n\u001b[0;32m     53\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     54\u001b[0m     factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,        \u001b[38;5;66;03m# reduce by half\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,         \u001b[38;5;66;03m# after 3 bad epochs\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m         \u001b[38;5;66;03m# never go below this\u001b[39;00m\n\u001b[0;32m     57\u001b[0m )\n\u001b[1;32m---> 60\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     61\u001b[0m     X_train_seq,y_train_seq,\n\u001b[0;32m     62\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val_seq, y_val_seq),\n\u001b[0;32m     63\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m     64\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# callbacks=[early_stop]\u001b[39;00m\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     67\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_seq)  \n\u001b[0;32m     68\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_proba\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:401\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    392\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    393\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    400\u001b[0m     )\n\u001b[1;32m--> 401\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m    402\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    403\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m    404\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mval_sample_weight,\n\u001b[0;32m    405\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mvalidation_batch_size \u001b[38;5;129;01mor\u001b[39;00m batch_size,\n\u001b[0;32m    406\u001b[0m     steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m    407\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    408\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    409\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    410\u001b[0m )\n\u001b[0;32m    411\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    413\u001b[0m }\n\u001b[0;32m    414\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:489\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    488\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(begin_step)\n\u001b[1;32m--> 489\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function(iterator)\n\u001b[0;32m    490\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(end_step, logs)\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_evaluating:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1689\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1690\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1691\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1692\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1693\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1694\u001b[0m   )\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_2_features = ['market_return', 'Weighted_Strength', 'mean_return_others','TSLA', 'AAPL', 'NVDA', 'MSFT']\n",
    "X_2 = X[X_2_features]\n",
    "\n",
    "train_size = int(len(X_2) * 0.70)\n",
    "val_size = int(len(X_2) * 0.85)\n",
    "X_train, X_val, X_test = X_2[0:train_size], X_2[train_size:val_size], X_2[val_size:len(X_2)]\n",
    "y_train, y_val, y_test = y[0:train_size], y[train_size:val_size], y[val_size:len(y)]\n",
    "print(len(X_train), len(X_test), len(X_val), len(y_train), len(y_test), len(y_val))\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "X_val_scaled  = scaler.transform(X_val)\n",
    "\n",
    "time_stamp = 20\n",
    "features = len(X_2.columns)\n",
    "X_train_seq, y_train_seq = creat_sequence(X_train_scaled, y_train, time_stamp)\n",
    "X_val_seq, y_val_seq = creat_sequence(X_val_scaled, y_val, time_stamp)\n",
    "X_test_seq, y_test_seq = creat_sequence(X_test_scaled, y_test, time_stamp)\n",
    "print(X_train_seq.shape, y_train_seq.shape)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=128, input_shape=(time_stamp, features), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "          \n",
    "model.add(LSTM(units=64, return_sequences=True)) \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=32, return_sequences=False))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "optimizer = AdamW(learning_rate=0.005)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,        # reduce by half\n",
    "    patience=3,         # after 3 bad epochs\n",
    "    min_lr=1e-6         # never go below this\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    X_train_seq,y_train_seq,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    # callbacks=[early_stop]\n",
    ")\n",
    "y_proba = model.predict(X_test_seq)  \n",
    "y_pred = (y_proba.ravel() >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test_seq, y_pred))\n",
    "print(confusion_matrix(y_test_seq, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dc776154-c963-4ab2-84e7-b908b072e0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5392 - loss: 0.6911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6910983324050903, 0.5391849279403687]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_seq,y_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f579860d-2e7c-42d6-86bc-a883f953a797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_test_seq, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "14257c44-5868-46cc-b94b-43bd5d8fed1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1], dtype=int64), array([3513, 4001], dtype=int64)),\n",
       " dtype('int64'))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_seq, return_counts=True), y_train_seq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1e9fc279-6f75-4071-a0c2-4ba74c92ff95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e04d38-436b-4a1d-aab9-dbf37403a7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
