{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ae666b-8dd9-4108-89a5-b009a5013a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4be25af-1e59-4bef-af9c-1c0ade34858d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target</th>\n",
       "      <th>RAV</th>\n",
       "      <th>volatility</th>\n",
       "      <th>Buy_Sell_Strength</th>\n",
       "      <th>Weighted_Strength</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Returns</th>\n",
       "      <th>Log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>return_2</th>\n",
       "      <th>vol_3</th>\n",
       "      <th>close_z</th>\n",
       "      <th>market_mean_return</th>\n",
       "      <th>pol_mean</th>\n",
       "      <th>pol_sum</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>neu_count</th>\n",
       "      <th>has_news</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-06</th>\n",
       "      <td>26.495508</td>\n",
       "      <td>174826400</td>\n",
       "      <td>1</td>\n",
       "      <td>2.508224e+08</td>\n",
       "      <td>1.046604</td>\n",
       "      <td>0.266668</td>\n",
       "      <td>-0.162635</td>\n",
       "      <td>-0.007055</td>\n",
       "      <td>-0.008421</td>\n",
       "      <td>8.064544</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-06</th>\n",
       "      <td>36.218159</td>\n",
       "      <td>34616600</td>\n",
       "      <td>0</td>\n",
       "      <td>5.097210e+07</td>\n",
       "      <td>2.133874</td>\n",
       "      <td>0.406248</td>\n",
       "      <td>-0.063670</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>10.087210</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-06</th>\n",
       "      <td>0.489517</td>\n",
       "      <td>210524000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.155857e+08</td>\n",
       "      <td>0.010619</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>-0.268543</td>\n",
       "      <td>0.023777</td>\n",
       "      <td>-0.004392</td>\n",
       "      <td>-0.689525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008421</td>\n",
       "      <td>1.063699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-06</th>\n",
       "      <td>14.490667</td>\n",
       "      <td>48658500</td>\n",
       "      <td>1</td>\n",
       "      <td>5.486293e+07</td>\n",
       "      <td>0.608197</td>\n",
       "      <td>0.124639</td>\n",
       "      <td>-0.332912</td>\n",
       "      <td>0.016009</td>\n",
       "      <td>-0.016426</td>\n",
       "      <td>5.386730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>0.917563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-09</th>\n",
       "      <td>26.671497</td>\n",
       "      <td>155559200</td>\n",
       "      <td>1</td>\n",
       "      <td>2.247958e+08</td>\n",
       "      <td>1.096022</td>\n",
       "      <td>0.914897</td>\n",
       "      <td>0.287110</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>8.139060</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Close     Volume  Target           RAV  volatility  \\\n",
       "date                                                                 \n",
       "2015-02-06  26.495508  174826400       1  2.508224e+08    1.046604   \n",
       "2015-02-06  36.218159   34616600       0  5.097210e+07    2.133874   \n",
       "2015-02-06   0.489517  210524000       0  2.155857e+08    0.010619   \n",
       "2015-02-06  14.490667   48658500       1  5.486293e+07    0.608197   \n",
       "2015-02-09  26.671497  155559200       1  2.247958e+08    1.096022   \n",
       "\n",
       "            Buy_Sell_Strength  Weighted_Strength     Trend   Returns  \\\n",
       "date                                                                   \n",
       "2015-02-06           0.266668          -0.162635 -0.007055 -0.008421   \n",
       "2015-02-06           0.406248          -0.063670  0.022419 -0.000942   \n",
       "2015-02-06           0.225000          -0.268543  0.023777 -0.004392   \n",
       "2015-02-06           0.124639          -0.332912  0.016009 -0.016426   \n",
       "2015-02-09           0.914897           0.287110  0.010177  0.006642   \n",
       "\n",
       "            Log_returns  ...  return_2     vol_3  close_z  market_mean_return  \\\n",
       "date                     ...                                                    \n",
       "2015-02-06     8.064544  ...       NaN       NaN      NaN           -0.007545   \n",
       "2015-02-06    10.087210  ...       NaN       NaN      NaN           -0.007545   \n",
       "2015-02-06    -0.689525  ... -0.008421  1.063699      NaN           -0.007545   \n",
       "2015-02-06     5.386730  ... -0.000942  0.917563      NaN           -0.007545   \n",
       "2015-02-09     8.139060  ...       NaN  0.571613      NaN            0.001259   \n",
       "\n",
       "            pol_mean  pol_sum  pos_count  neg_count  neu_count  has_news  \n",
       "date                                                                      \n",
       "2015-02-06       0.0      0.0        0.0        0.0        0.0         0  \n",
       "2015-02-06       0.0      0.0        0.0        0.0        0.0         0  \n",
       "2015-02-06       0.0      0.0        0.0        0.0        0.0         0  \n",
       "2015-02-06       0.0      0.0        0.0        0.0        0.0         0  \n",
       "2015-02-09       0.0      0.0        0.0        1.0        0.0         1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/stock_with_sentiment.csv\",index_col=\"date\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc0d56ce-b43c-4329-ade0-5e76dd265b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10804 entries, 2015-02-06 to 2025-10-31\n",
      "Data columns (total 34 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Close               10804 non-null  float64\n",
      " 1   Volume              10804 non-null  int64  \n",
      " 2   Target              10804 non-null  int64  \n",
      " 3   RAV                 10804 non-null  float64\n",
      " 4   volatility          10804 non-null  float64\n",
      " 5   Buy_Sell_Strength   10804 non-null  float64\n",
      " 6   Weighted_Strength   10804 non-null  float64\n",
      " 7   Trend               10804 non-null  float64\n",
      " 8   Returns             10804 non-null  float64\n",
      " 9   Log_returns         10804 non-null  float64\n",
      " 10  AAPL                10804 non-null  bool   \n",
      " 11  MSFT                10804 non-null  bool   \n",
      " 12  NVDA                10804 non-null  bool   \n",
      " 13  TSLA                10804 non-null  bool   \n",
      " 14  market_return       10804 non-null  float64\n",
      " 15  rel_return          10804 non-null  float64\n",
      " 16  mean_return_others  10804 non-null  float64\n",
      " 17  divergence          10804 non-null  float64\n",
      " 18  volume_rank         10804 non-null  float64\n",
      " 19  return_rank         10804 non-null  float64\n",
      " 20  lag_market_return   8103 non-null   float64\n",
      " 21  market_std          10804 non-null  float64\n",
      " 22  zscore_vs_market    10804 non-null  float64\n",
      " 23  return_1            8103 non-null   float64\n",
      " 24  return_2            5402 non-null   float64\n",
      " 25  vol_3               10802 non-null  float64\n",
      " 26  close_z             10795 non-null  float64\n",
      " 27  market_mean_return  10804 non-null  float64\n",
      " 28  pol_mean            10804 non-null  float64\n",
      " 29  pol_sum             10804 non-null  float64\n",
      " 30  pos_count           10804 non-null  float64\n",
      " 31  neg_count           10804 non-null  float64\n",
      " 32  neu_count           10804 non-null  float64\n",
      " 33  has_news            10804 non-null  int64  \n",
      "dtypes: bool(4), float64(27), int64(3)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d59a5943-59ed-49d9-817a-18d4edee2e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10804 10804\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Target','lag_market_return','close_z', 'vol_3', 'return_2', 'return_1',\"market_mean_return\"], axis=\"columns\")\n",
    "y = np.array(df['Target'])\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fec1849-929b-4141-83ff-16d86b4e730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7562 1621 1621 7562 1621 1621\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(X) * 0.70)\n",
    "val_size = int(len(X) * 0.85)\n",
    "X_train, X_val, X_test = X[0:train_size], X[train_size:val_size], X[val_size:len(X)]\n",
    "y_train, y_val, y_test = y[0:train_size], y[train_size:val_size], y[val_size:len(y)]\n",
    "print(len(X_train), len(X_test), len(X_val), len(y_train), len(y_test), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6893446a-56f9-4720-bf3a-efe1f7dfd4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "X_val_scaled  = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75f4b72d-f420-4658-883e-83c3112839cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_sequence(X, y, time_stamp=5):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_stamp):\n",
    "        Xs.append(X[i:(i + time_stamp)])\n",
    "        ys.append(y[i + time_stamp])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b526d8c-8818-4078-83e3-19b237f96c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7542, 20, 27) (7542,)\n",
      "(1601, 20, 27) (1601,)\n",
      "(1601, 20, 27) (1601,)\n"
     ]
    }
   ],
   "source": [
    "time_stamp = 20\n",
    "features = len(X.columns)\n",
    "X_train_seq, y_train_seq = creat_sequence(X_train_scaled, y_train, time_stamp)\n",
    "X_val_seq, y_val_seq = creat_sequence(X_val_scaled, y_val, time_stamp)\n",
    "X_test_seq, y_test_seq = creat_sequence(X_test_scaled, y_test, time_stamp)\n",
    "\n",
    "print(X_train_seq.shape, y_train_seq.shape)\n",
    "print(X_val_seq.shape, y_val_seq.shape)\n",
    "print(X_test_seq.shape, y_test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efe39696-17e0-4a25-9064-28613331b6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence 0\n",
      "X window indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Target index: 20\n",
      "y target: 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "sequence 1\n",
      "X window indices: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "Target index: 21\n",
      "y target: 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "sequence 2\n",
      "X window indices: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "Target index: 22\n",
      "y target: 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "sequence 3\n",
      "X window indices: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Target index: 23\n",
      "y target: 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "sequence 4\n",
      "X window indices: [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "Target index: 24\n",
      "y target: 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"sequence {i}\")\n",
    "    print(\"X window indices:\", list(range(i, i + time_stamp)))\n",
    "    print(\"Target index:\", i + time_stamp)\n",
    "    print(\"y target:\", y[i + time_stamp])\n",
    "    print(\"-\" * 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2c96c8d-0495-477d-9c9a-c6628b5f4ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 99ms/step - accuracy: 0.5302 - loss: 0.6943 - val_accuracy: 0.5215 - val_loss: 0.6922\n",
      "Epoch 2/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.5270 - loss: 0.6921 - val_accuracy: 0.5215 - val_loss: 0.6921\n",
      "Epoch 3/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.5302 - loss: 0.6911 - val_accuracy: 0.5215 - val_loss: 0.6936\n",
      "Epoch 4/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.5326 - loss: 0.6910 - val_accuracy: 0.5215 - val_loss: 0.6920\n",
      "Epoch 5/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.5333 - loss: 0.6909 - val_accuracy: 0.5215 - val_loss: 0.6936\n",
      "Epoch 6/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.5320 - loss: 0.6905 - val_accuracy: 0.5178 - val_loss: 0.6928\n",
      "Epoch 7/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.5362 - loss: 0.6895 - val_accuracy: 0.5122 - val_loss: 0.6930\n",
      "Epoch 8/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.5288 - loss: 0.6898 - val_accuracy: 0.5147 - val_loss: 0.6939\n",
      "Epoch 9/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.5371 - loss: 0.6890 - val_accuracy: 0.5109 - val_loss: 0.6934\n",
      "Epoch 10/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.5387 - loss: 0.6886 - val_accuracy: 0.5222 - val_loss: 0.6935\n",
      "Epoch 11/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.5301 - loss: 0.6880 - val_accuracy: 0.5103 - val_loss: 0.6930\n",
      "Epoch 12/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.5359 - loss: 0.6884 - val_accuracy: 0.5097 - val_loss: 0.6931\n",
      "Epoch 13/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.5383 - loss: 0.6877 - val_accuracy: 0.5222 - val_loss: 0.6928\n",
      "Epoch 14/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.5410 - loss: 0.6866 - val_accuracy: 0.4841 - val_loss: 0.7019\n",
      "Epoch 15/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.5281 - loss: 0.6886 - val_accuracy: 0.5109 - val_loss: 0.6986\n",
      "Epoch 16/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.5415 - loss: 0.6870 - val_accuracy: 0.5159 - val_loss: 0.6946\n",
      "Epoch 17/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.5422 - loss: 0.6866 - val_accuracy: 0.5141 - val_loss: 0.6928\n",
      "Epoch 18/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.5365 - loss: 0.6865 - val_accuracy: 0.5159 - val_loss: 0.6957\n",
      "Epoch 19/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - accuracy: 0.5456 - loss: 0.6860 - val_accuracy: 0.5066 - val_loss: 0.6915\n",
      "Epoch 20/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.5456 - loss: 0.6853 - val_accuracy: 0.5053 - val_loss: 0.6921\n",
      "Epoch 21/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.5467 - loss: 0.6852 - val_accuracy: 0.5265 - val_loss: 0.6905\n",
      "Epoch 22/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.5455 - loss: 0.6849 - val_accuracy: 0.5172 - val_loss: 0.6935\n",
      "Epoch 23/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.5472 - loss: 0.6834 - val_accuracy: 0.5153 - val_loss: 0.6965\n",
      "Epoch 24/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - accuracy: 0.5472 - loss: 0.6827 - val_accuracy: 0.5128 - val_loss: 0.6986\n",
      "Epoch 25/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.5525 - loss: 0.6814 - val_accuracy: 0.4959 - val_loss: 0.7070\n",
      "Epoch 26/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - accuracy: 0.5508 - loss: 0.6817 - val_accuracy: 0.4978 - val_loss: 0.7069\n",
      "Epoch 27/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.5570 - loss: 0.6810 - val_accuracy: 0.4934 - val_loss: 0.7011\n",
      "Epoch 28/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.5603 - loss: 0.6790 - val_accuracy: 0.5172 - val_loss: 0.6980\n",
      "Epoch 29/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - accuracy: 0.5642 - loss: 0.6784 - val_accuracy: 0.4847 - val_loss: 0.7085\n",
      "Epoch 30/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.5630 - loss: 0.6759 - val_accuracy: 0.5034 - val_loss: 0.7268\n",
      "Epoch 31/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.5644 - loss: 0.6764 - val_accuracy: 0.4922 - val_loss: 0.7061\n",
      "Epoch 32/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - accuracy: 0.5732 - loss: 0.6710 - val_accuracy: 0.5041 - val_loss: 0.6998\n",
      "Epoch 33/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.5764 - loss: 0.6711 - val_accuracy: 0.5172 - val_loss: 0.7123\n",
      "Epoch 34/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.5756 - loss: 0.6686 - val_accuracy: 0.4891 - val_loss: 0.7369\n",
      "Epoch 35/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - accuracy: 0.5826 - loss: 0.6673 - val_accuracy: 0.5072 - val_loss: 0.7301\n",
      "Epoch 36/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.5831 - loss: 0.6642 - val_accuracy: 0.5147 - val_loss: 0.7298\n",
      "Epoch 37/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.5868 - loss: 0.6592 - val_accuracy: 0.5066 - val_loss: 0.7216\n",
      "Epoch 38/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.5939 - loss: 0.6567 - val_accuracy: 0.4735 - val_loss: 0.7582\n",
      "Epoch 39/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.5927 - loss: 0.6554 - val_accuracy: 0.5034 - val_loss: 0.7637\n",
      "Epoch 40/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.6013 - loss: 0.6499 - val_accuracy: 0.5078 - val_loss: 0.7308\n",
      "Epoch 41/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.6098 - loss: 0.6435 - val_accuracy: 0.5047 - val_loss: 0.7846\n",
      "Epoch 42/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - accuracy: 0.6128 - loss: 0.6402 - val_accuracy: 0.4816 - val_loss: 0.7868\n",
      "Epoch 43/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - accuracy: 0.6163 - loss: 0.6337 - val_accuracy: 0.4760 - val_loss: 0.8359\n",
      "Epoch 44/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.6195 - loss: 0.6276 - val_accuracy: 0.4941 - val_loss: 0.8173\n",
      "Epoch 45/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.6229 - loss: 0.6224 - val_accuracy: 0.4728 - val_loss: 0.9511\n",
      "Epoch 46/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - accuracy: 0.6344 - loss: 0.6169 - val_accuracy: 0.4822 - val_loss: 0.8849\n",
      "Epoch 47/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.6419 - loss: 0.6098 - val_accuracy: 0.4916 - val_loss: 0.8281\n",
      "Epoch 48/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.6470 - loss: 0.6033 - val_accuracy: 0.4859 - val_loss: 0.9337\n",
      "Epoch 49/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - accuracy: 0.6534 - loss: 0.5937 - val_accuracy: 0.4847 - val_loss: 1.0087\n",
      "Epoch 50/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.6672 - loss: 0.5842 - val_accuracy: 0.4703 - val_loss: 1.0198\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">79,872</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m79,872\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,181</span> (1.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m394,181\u001b[0m (1.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,393</span> (513.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m131,393\u001b[0m (513.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262,788</span> (1.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m262,788\u001b[0m (1.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_crossentropy <keras.src.optimizers.adam.Adam object at 0x000002586B3CD070>\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5353 - loss: 0.8051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8051102161407471, 0.5352904200553894]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Python\n",
    "random.seed(SEED)\n",
    "\n",
    "# NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# TensorFlow\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Force reproducibility inside TF\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "\n",
    "\n",
    "\n",
    "#Define the model\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(LSTM(units=128, input_shape=(time_stamp, features), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=64, return_sequences=False))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(LSTM(units=32, return_sequences=False))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "# Add a Dense output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=0.001,  clipnorm=1.0)\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_seq,\n",
    "    y_train_seq,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    shuffle=False,\n",
    "    # callbacks=[early_stop]\n",
    ")\n",
    "model.summary()\n",
    "print(model.loss, model.optimizer)\n",
    "model.evaluate(X_test_seq,y_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c189082-fb2d-4221-b4a9-df4099a6f3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.48      0.49       733\n",
      "           1       0.57      0.58      0.57       868\n",
      "\n",
      "    accuracy                           0.54      1601\n",
      "   macro avg       0.53      0.53      0.53      1601\n",
      "weighted avg       0.53      0.54      0.53      1601\n",
      "\n",
      "[[354 379]\n",
      " [365 503]]\n",
      "[[0.45259878]\n",
      " [0.84189624]\n",
      " [0.90071005]\n",
      " [0.8987608 ]\n",
      " [0.401319  ]]\n",
      "LSTM [719 882]\n"
     ]
    }
   ],
   "source": [
    "y_proba = model.predict(X_test_seq)  \n",
    "y_pred = (y_proba.ravel() >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test_seq, y_pred))\n",
    "print(confusion_matrix(y_test_seq, y_pred))\n",
    "print(y_proba[:5])\n",
    "print(\"LSTM\",np.bincount(y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b06f70a9-5f9e-4603-a96a-3b02d4ace92b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.5296 - loss: 0.6928 - val_accuracy: 0.5215 - val_loss: 0.6926\n",
      "Epoch 2/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.5298 - loss: 0.6915 - val_accuracy: 0.5215 - val_loss: 0.6925\n",
      "Epoch 3/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.5304 - loss: 0.6912 - val_accuracy: 0.5215 - val_loss: 0.6923\n",
      "Epoch 4/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.5325 - loss: 0.6911 - val_accuracy: 0.5215 - val_loss: 0.6924\n",
      "Epoch 5/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.5334 - loss: 0.6908 - val_accuracy: 0.5147 - val_loss: 0.6925\n",
      "Epoch 6/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.5316 - loss: 0.6901 - val_accuracy: 0.5128 - val_loss: 0.6926\n",
      "Epoch 7/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.5265 - loss: 0.6894 - val_accuracy: 0.5191 - val_loss: 0.6925\n",
      "Epoch 8/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.5334 - loss: 0.6889 - val_accuracy: 0.5172 - val_loss: 0.6925\n",
      "Epoch 9/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.5350 - loss: 0.6886 - val_accuracy: 0.5097 - val_loss: 0.6928\n",
      "Epoch 10/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.5345 - loss: 0.6884 - val_accuracy: 0.5134 - val_loss: 0.6925\n",
      "Epoch 11/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.5355 - loss: 0.6883 - val_accuracy: 0.5153 - val_loss: 0.6925\n",
      "Epoch 12/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - accuracy: 0.5399 - loss: 0.6882 - val_accuracy: 0.5103 - val_loss: 0.6923\n",
      "Epoch 13/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.5403 - loss: 0.6880 - val_accuracy: 0.5097 - val_loss: 0.6924\n",
      "Epoch 14/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.5390 - loss: 0.6879 - val_accuracy: 0.5191 - val_loss: 0.6921\n",
      "Epoch 15/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.5411 - loss: 0.6876 - val_accuracy: 0.5166 - val_loss: 0.6919\n",
      "Epoch 16/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.5451 - loss: 0.6872 - val_accuracy: 0.5215 - val_loss: 0.6918\n",
      "Epoch 17/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.5432 - loss: 0.6872 - val_accuracy: 0.5184 - val_loss: 0.6920\n",
      "Epoch 18/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.5430 - loss: 0.6871 - val_accuracy: 0.5184 - val_loss: 0.6921\n",
      "Epoch 19/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.5391 - loss: 0.6868 - val_accuracy: 0.5122 - val_loss: 0.6919\n",
      "Epoch 20/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.5407 - loss: 0.6862 - val_accuracy: 0.5203 - val_loss: 0.6937\n",
      "Epoch 21/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - accuracy: 0.5451 - loss: 0.6856 - val_accuracy: 0.5222 - val_loss: 0.6945\n",
      "Epoch 22/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.5472 - loss: 0.6848 - val_accuracy: 0.5072 - val_loss: 0.6961\n",
      "Epoch 23/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.5489 - loss: 0.6856 - val_accuracy: 0.5184 - val_loss: 0.6970\n",
      "Epoch 24/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.5496 - loss: 0.6840 - val_accuracy: 0.5097 - val_loss: 0.6957\n",
      "Epoch 25/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.5487 - loss: 0.6844 - val_accuracy: 0.5072 - val_loss: 0.7008\n",
      "Epoch 26/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.5524 - loss: 0.6826 - val_accuracy: 0.5084 - val_loss: 0.7005\n",
      "Epoch 27/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.5503 - loss: 0.6828 - val_accuracy: 0.5047 - val_loss: 0.6997\n",
      "Epoch 28/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.5501 - loss: 0.6856 - val_accuracy: 0.5272 - val_loss: 0.6963\n",
      "Epoch 29/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.5554 - loss: 0.6808 - val_accuracy: 0.5084 - val_loss: 0.7040\n",
      "Epoch 30/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.5567 - loss: 0.6802 - val_accuracy: 0.5116 - val_loss: 0.7105\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">79,872</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_40 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m79,872\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_41 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,181</span> (1.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m394,181\u001b[0m (1.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,393</span> (513.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m131,393\u001b[0m (513.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262,788</span> (1.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m262,788\u001b[0m (1.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_crossentropy <keras.src.optimizers.adam.Adam object at 0x00000258207478C0>\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4697 - loss: 0.7554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7554135918617249, 0.4697064459323883]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Python\n",
    "random.seed(SEED)\n",
    "\n",
    "# NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# TensorFlow\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Force reproducibility inside TF\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "\n",
    "\n",
    "\n",
    "#Define the model\n",
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "\n",
    "model_1.add(LSTM(units=128, input_shape=(time_stamp, features), return_sequences=True))\n",
    "model_1.add(Dropout(0.1))\n",
    "\n",
    "model_1.add(LSTM(units=64, return_sequences=False))\n",
    "# model_1.add(Dropout(0.1))\n",
    "\n",
    "# model_1.add(LSTM(units=32, return_sequences=False))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model_1.add(Dense(32, activation=\"tanh\"))\n",
    "# Add a Dense output layer\n",
    "model_1.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=0.001,  clipnorm=1.0)\n",
    "model_1.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_1.fit(\n",
    "    X_train_seq,\n",
    "    y_train_seq,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    batch_size=64,\n",
    "    epochs=30,\n",
    "    shuffle=False,\n",
    "    # callbacks=[early_stop]\n",
    ")\n",
    "model_1.summary()\n",
    "print(model_1.loss, model_1.optimizer)\n",
    "model_1.evaluate(X_test_seq,y_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "519f979f-3dc2-490e-ac8f-7aa1165dfe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.80      0.58       733\n",
      "           1       0.53      0.19      0.28       868\n",
      "\n",
      "    accuracy                           0.47      1601\n",
      "   macro avg       0.49      0.50      0.43      1601\n",
      "weighted avg       0.50      0.47      0.42      1601\n",
      "\n",
      "[[583 150]\n",
      " [699 169]]\n",
      "[[0.48642346]\n",
      " [0.44464108]\n",
      " [0.42095238]\n",
      " [0.40548056]\n",
      " [0.38535553]]\n",
      "LSTM [1282  319]\n"
     ]
    }
   ],
   "source": [
    "y_proba_1 = model_1.predict(X_test_seq)  \n",
    "y_pred_1 = (y_proba_1.ravel() >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test_seq, y_pred_1))\n",
    "print(confusion_matrix(y_test_seq, y_pred_1))\n",
    "print(y_proba_1[:5])\n",
    "print(\"LSTM\",np.bincount(y_pred_1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5e64df2-e5d5-4fb3-b7e8-1c6b03bbd46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/v3.1(sentiment)_lstm_stock_pediction.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# joblib.dump(model,'../models/v3.1(sentiment)_lstm_stock_pediction.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ab4a6-95d1-4092-b8b3-7c0f05d14669",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2_features = ['market_return', 'Weighted_Strength', 'mean_return_others','TSLA', 'AAPL', 'NVDA', 'MSFT','pol_mean', 'pol_sum', 'pos_count' ,'neg_count', 'neu_count', 'has_news']\n",
    "X_2 = X[X_2_features]\n",
    "\n",
    "train_size = int(len(X_2) * 0.70)\n",
    "val_size = int(len(X_2) * 0.85)\n",
    "X_train, X_val, X_test = X_2[0:train_size], X_2[train_size:val_size], X_2[val_size:len(X_2)]\n",
    "y_train, y_val, y_test = y[0:train_size], y[train_size:val_size], y[val_size:len(y)]\n",
    "print(len(X_train), len(X_test), len(X_val), len(y_train), len(y_test), len(y_val))\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "X_val_scaled  = scaler.transform(X_val)\n",
    "\n",
    "time_stamp = 20\n",
    "features = len(X_2.columns)\n",
    "X_train_seq, y_train_seq = creat_sequence(X_train_scaled, y_train, time_stamp)\n",
    "X_val_seq, y_val_seq = creat_sequence(X_val_scaled, y_val, time_stamp)\n",
    "X_test_seq, y_test_seq = creat_sequence(X_test_scaled, y_test, time_stamp)\n",
    "print(X_train_seq.shape, y_train_seq.shape)\n",
    "\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(LSTM(units=128, input_shape=(time_stamp, features), return_sequences=True))\n",
    "model_2.add(Dropout(0.2))\n",
    "          \n",
    "model_2.add(LSTM(units=64, return_sequences=True)) \n",
    "model_2.add(Dropout(0.2))\n",
    "\n",
    "model_2.add(LSTM(units=32, return_sequences=False))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model_2.add(Dense(64, activation=\"tanh\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "optimizer = AdamW(learning_rate=0.005)\n",
    "\n",
    "model_2.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,        # reduce by half\n",
    "    patience=3,         # after 3 bad epochs\n",
    "    min_lr=1e-6         # never go below this\n",
    ")\n",
    "\n",
    "\n",
    "model_2.fit(\n",
    "    X_train_seq,y_train_seq,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    # callbacks=[early_stop]\n",
    ")\n",
    "model_2.evaluate(X_test_seq,y_test_seq)\n",
    "\n",
    "y_proba = model_2.predict(X_test_seq)  \n",
    "y_pred = (y_proba.ravel() >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test_seq, y_pred))\n",
    "print(confusion_matrix(y_test_seq, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
